{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0d555d2-52f9-4edf-91eb-07944b725a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "kedb_data = pd.read_csv('kedb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fdf200e-a1f4-4441-aecb-5540a08f06b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventTypeName</th>\n",
       "      <th>Cluster no</th>\n",
       "      <th>Message</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Status</th>\n",
       "      <th>Processed_Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAM Warning</td>\n",
       "      <td>2</td>\n",
       "      <td>Component \"Worker Process Statistic Monitor (C...</td>\n",
       "      <td>2025-02-18 00:15:31</td>\n",
       "      <td>warning</td>\n",
       "      <td>Component Worker Process Statistic Monitor CCM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SAM Warning</td>\n",
       "      <td>2</td>\n",
       "      <td>Component \"Worker Process Statistic Monitor (S...</td>\n",
       "      <td>2025-02-18 00:15:31</td>\n",
       "      <td>warning</td>\n",
       "      <td>Component Worker Process Statistic Monitor SMS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SAM Warning</td>\n",
       "      <td>2</td>\n",
       "      <td>Component \"Worker Process Statistic Monitor (I...</td>\n",
       "      <td>2025-02-18 00:15:31</td>\n",
       "      <td>warning</td>\n",
       "      <td>Component Worker Process Statistic Monitor ISM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SAM Warning</td>\n",
       "      <td>2</td>\n",
       "      <td>Component \"Active Directory Domain Services\" f...</td>\n",
       "      <td>2025-02-18 00:15:31</td>\n",
       "      <td>warning</td>\n",
       "      <td>Component Active Directory Domain Services app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SAM Warning</td>\n",
       "      <td>2</td>\n",
       "      <td>Application \"NOC Infra - Active Directory Doma...</td>\n",
       "      <td>2025-02-18 00:15:31</td>\n",
       "      <td>warning</td>\n",
       "      <td>Application NOC Infra Active Directory Domain ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  EventTypeName  Cluster no  \\\n",
       "0   SAM Warning           2   \n",
       "1   SAM Warning           2   \n",
       "2   SAM Warning           2   \n",
       "3   SAM Warning           2   \n",
       "4   SAM Warning           2   \n",
       "\n",
       "                                             Message            Timestamp  \\\n",
       "0  Component \"Worker Process Statistic Monitor (C...  2025-02-18 00:15:31   \n",
       "1  Component \"Worker Process Statistic Monitor (S...  2025-02-18 00:15:31   \n",
       "2  Component \"Worker Process Statistic Monitor (I...  2025-02-18 00:15:31   \n",
       "3  Component \"Active Directory Domain Services\" f...  2025-02-18 00:15:31   \n",
       "4  Application \"NOC Infra - Active Directory Doma...  2025-02-18 00:15:31   \n",
       "\n",
       "    Status                                  Processed_Message  \n",
       "0  warning  Component Worker Process Statistic Monitor CCM...  \n",
       "1  warning  Component Worker Process Statistic Monitor SMS...  \n",
       "2  warning  Component Worker Process Statistic Monitor ISM...  \n",
       "3  warning  Component Active Directory Domain Services app...  \n",
       "4  warning  Application NOC Infra Active Directory Domain ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kedb_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b3745ac-47a8-4858-b4c2-3f8dad49fe34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a33c5b-5421-4729-b87c-a0e3a4b53142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9096dbb3-8f0c-4b18-92a7-5724984764bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Timestamp column to datetime format\n",
    "kedb_data['Timestamp'] = pd.to_datetime(kedb_data['Timestamp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00ec4eb8-7e4f-487f-9cf3-421ff4281c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_processed_message(keyword=None, status=None, cluster=None):\n",
    "    \"\"\"\n",
    "    Query the Processed_Message column based on keyword, status, or cluster.\n",
    "    \"\"\"\n",
    "    filtered_data = kedb_data\n",
    "    if keyword:\n",
    "        filtered_data = filtered_data[filtered_data['Processed_Message'].str.contains(keyword, case=False, na=False)]\n",
    "    if status:\n",
    "        filtered_data = filtered_data[filtered_data['Status'].str.lower() == status.lower()]\n",
    "    if cluster:\n",
    "        filtered_data = filtered_data[filtered_data['Cluster no'] == cluster]\n",
    "\n",
    "    return filtered_data[['Timestamp', 'Cluster no', 'Status', 'Processed_Message']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "135d72f1-bb2f-420f-9c36-4ba7583d59bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_processed_messages():\n",
    "    \"\"\"\n",
    "    Analyze the Processed_Message column to provide insights.\n",
    "    \"\"\"\n",
    "    most_common = kedb_data['Processed_Message'].value_counts().head(5)\n",
    "    status_counts = kedb_data['Status'].value_counts()\n",
    "\n",
    "    return {\n",
    "        'Most Common Messages': most_common,\n",
    "        'Status Distribution': status_counts\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf0840f3-c44b-4101-9693-6a854ff30b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def provide_suggestions():\n",
    "    \"\"\"\n",
    "    Suggest actions based on common patterns in Processed_Message.\n",
    "    \"\"\"\n",
    "    suggestions = []\n",
    "    \n",
    "    if 'Active Directory' in ' '.join(kedb_data['Processed_Message'].tolist()):\n",
    "        suggestions.append(\"Investigate Active Directory processes.\")\n",
    "    \n",
    "    if kedb_data['Status'].str.contains('critical', case=False, na=False).any():\n",
    "        suggestions.append(\"Address critical issues immediately.\")\n",
    "    \n",
    "    if kedb_data['Cluster no'].value_counts().max() > 10:\n",
    "        suggestions.append(\"Check clusters with high event frequency.\")\n",
    "\n",
    "    return suggestions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5e0fc85-c469-4060-9f22-115f13fb3289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_response(user_query):\n",
    "    \"\"\"\n",
    "    Process user queries and search the KEDB for relevant results.\n",
    "    \"\"\"\n",
    "    # Parse the user query for keywords, status, or cluster\n",
    "    keywords = [word for word in user_query.split() if len(word) > 3]\n",
    "    status = None\n",
    "    cluster = None\n",
    "\n",
    "    # Attempt to identify status or cluster in the query\n",
    "    if \"warning\" in user_query.lower():\n",
    "        status = \"warning\"\n",
    "    elif \"critical\" in user_query.lower():\n",
    "        status = \"critical\"\n",
    "\n",
    "    if \"cluster\" in user_query.lower():\n",
    "        try:\n",
    "            cluster = int([word for word in user_query.split() if word.isdigit()][0])\n",
    "        except IndexError:\n",
    "            cluster = None\n",
    "\n",
    "    # Search the KEDB\n",
    "    results = query_processed_message(keyword=\" \".join(keywords), status=status, cluster=cluster)\n",
    "\n",
    "    # Format the response\n",
    "    if not results.empty:\n",
    "        return results.to_dict('records')\n",
    "    else:\n",
    "        return \"No matching records found in the KEDB.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "117f8759-ecaa-4ce0-a28f-88277d048432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot Response:\n",
      "No matching records found in the KEDB.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Example chatbot interaction\n",
    "    user_query = \"Show me warning related ISNOCPRIVAPP0\"\n",
    "    print(\"Chatbot Response:\")\n",
    "    print(chatbot_response(user_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69a49035-e448-4fab-aa50-a3ddf183ed67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_csv(query, df):\n",
    "    # Convert the query to lowercase for case-insensitive search\n",
    "    query = query.lower()\n",
    "    \n",
    "    # Search the Processed_Message column for the query\n",
    "    results = df[df['Processed_Message'].str.lower().str.contains(query)]\n",
    "    \n",
    "    if not results.empty:\n",
    "        return results['Processed_Message'].tolist()\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af2991bc-3a7d-4bec-a4cb-9fabdf2b2c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(query):\n",
    "    # Search the CSV first\n",
    "    csv_results = search_csv(query, df)\n",
    "    \n",
    "    if csv_results:\n",
    "        return \"From CSV: \" + \", \".join(csv_results)\n",
    "    else:\n",
    "        # If not found in CSV, use OpenAI GPT\n",
    "        openai_answer = get_openai_answer(query)\n",
    "        return \"From OpenAI GPT: \" + openai_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c414c1e-ea4d-4b55-8c6b-dd1dea6388a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query: What will do on Warning state which device? due to member status on Intertec Perimter FW01?\n"
     ]
    },
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m queries:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser Query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m     response \u001b[38;5;241m=\u001b[39m chatbot(query)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatbot Response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[17], line 9\u001b[0m, in \u001b[0;36mchatbot\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrom CSV: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(csv_results)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# If not found in CSV, use OpenAI GPT\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     openai_answer \u001b[38;5;241m=\u001b[39m get_openai_answer(query)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrom OpenAI GPT: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m openai_answer\n",
      "Cell \u001b[1;32mIn[16], line 8\u001b[0m, in \u001b[0;36mget_openai_answer\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_openai_answer\u001b[39m(query):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Use OpenAI's GPT to generate a response\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mCompletion\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m      9\u001b[0m         engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-davinci-003\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# You can use \"gpt-4\" if you have access to it\u001b[39;00m\n\u001b[0;32m     10\u001b[0m         prompt\u001b[38;5;241m=\u001b[39mquery,\n\u001b[0;32m     11\u001b[0m         max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m,  \u001b[38;5;66;03m# Adjust based on the desired response length\u001b[39;00m\n\u001b[0;32m     12\u001b[0m         temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m  \u001b[38;5;66;03m# Adjust for creativity vs. determinism\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     )\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\openai\\lib\\_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[1;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "# Example queries\n",
    "queries = [\n",
    "    \"What will do on Warning state which device? due to member status on Intertec Perimter FW01?\",\n",
    "    \"What is the status of status on Intertec Perimter FW0?\",\n",
    "    \"I am not checking\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"User Query: {query}\")\n",
    "    response = chatbot(query)\n",
    "    print(f\"Chatbot Response: {response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6c9c50-e0ec-46bd-bbce-0dc4d1290357",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
